{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pointnet2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMcjYGTUL19JW0Rt+8z4yl4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hannah1123/Learning_Attention_is_all_you_need/blob/master/pointnet2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7aUpB-RCgM"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_sched\n",
        "\n",
        "from torch.utils.data import DataLoader, DistributedSampler\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8w7IXzOUwc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "outputId": "98eb13b2-62e6-4a80-e8cb-0149c88eb9e4"
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/9e/db4e1e3036e045a25d5c37617ded31a673a61f4befc62c5231818810b3a7/pytorch-lightning-0.7.1.tar.gz (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.18.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.2.0)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 41.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.27.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.6.0.post2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.34.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (46.0.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning) (2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning) (3.1.0)\n",
            "Building wheels for collected packages: pytorch-lightning, future\n",
            "  Building wheel for pytorch-lightning (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-lightning: filename=pytorch_lightning-0.7.1-cp36-none-any.whl size=145306 sha256=b91950c33dafa2922570c16134640063707f6daefcf5a3eb42493cd015644b94\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/93/61/14094d2116ff739513dda993007501ae5701b78386b39d5912\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=9f3297ff6609c369ff287ea7ad6f1d2fb14de80fc455a267d38b5efff1fdf82d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built pytorch-lightning future\n",
            "Installing collected packages: future, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2 pytorch-lightning-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxLV49DiROXa"
      },
      "source": [
        "import pytorch_lightning as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shE_L5RTRRVa"
      },
      "source": [
        "from pointnet2_ops.pointnet2_modules import PointnetFPModule, PointnetSAModule"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGi47ZCqU-L1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "431f8f1c-ca0f-4f59-fdc6-0c8909b3ec8e"
      },
      "source": [
        "lr_clip = 1e-5\n",
        "bnm_clip = 1e-2\n",
        "\n",
        "\n",
        "class PointNet2ClassificationSSG(pl.LightningModule):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hparams = args\n",
        "\n",
        "        self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.SA_modules = nn.ModuleList()\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                npoint=512,\n",
        "                radius=0.2,\n",
        "                nsample=64,\n",
        "                mlp=[3, 64, 64, 128],\n",
        "                use_xyz=self.hparams.model.use_xyz,\n",
        "            )\n",
        "        )\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                npoint=128,\n",
        "                radius=0.4,\n",
        "                nsample=64,\n",
        "                mlp=[128, 128, 128, 256],\n",
        "                use_xyz=self.hparams.model.use_xyz,\n",
        "            )\n",
        "        )\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                mlp=[256, 256, 512, 1024], use_xyz=self.hparams.model.use_xyz\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(1024, 512, bias=False),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 256, bias=False),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 40),\n",
        "        )\n",
        "        \n",
        "    def _break_up_pc(self, pc):\n",
        "        xyz = pc[..., 0:3].contiguous()\n",
        "        features = pc[..., 3:].transpose(1, 2).contiguous() if pc.size(-1) > 3 else None\n",
        "\n",
        "        return xyz, features\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        r\"\"\"\n",
        "            Forward pass of the network\n",
        "            Parameters\n",
        "            ----------\n",
        "            pointcloud: Variable(torch.cuda.FloatTensor)\n",
        "                (B, N, 3 + input_channels) tensor\n",
        "                Point cloud to run predicts on\n",
        "                Each point in the point-cloud MUST\n",
        "                be formated as (x, y, z, features...)\n",
        "        \"\"\"\n",
        "        xyz, features = self._break_up_pc(pointcloud)\n",
        "\n",
        "        for module in self.SA_modules:\n",
        "            xyz, features = module(xyz, features)\n",
        "\n",
        "        return self.fc_layer(features.squeeze(-1))\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        pc, labels = batch\n",
        "\n",
        "        logits = self.forward(pc)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        with torch.no_grad():\n",
        "            acc = (torch.argmax(logits, dim=1) == labels).float().mean()\n",
        "\n",
        "        log = dict(train_loss=loss, train_acc=acc)\n",
        "\n",
        "        return dict(loss=loss, log=log, progress_bar=dict(train_acc=acc))\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        pc, labels = batch\n",
        "\n",
        "        logits = self.forward(pc)\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        acc = (torch.argmax(logits, dim=1) == labels).float().mean()\n",
        "\n",
        "        return dict(val_loss=loss, val_acc=acc)\n",
        "\n",
        "    def validation_end(self, outputs):\n",
        "        reduced_outputs = {}\n",
        "        for k in outputs[0]:\n",
        "            for o in outputs:\n",
        "                reduced_outputs[k] = reduced_outputs.get(k, []) + [o[k]]\n",
        "\n",
        "        for k in reduced_outputs:\n",
        "            reduced_outputs[k] = torch.stack(reduced_outputs[k]).mean()\n",
        "\n",
        "        reduced_outputs.update(\n",
        "            dict(log=reduced_outputs.copy(), progress_bar=reduced_outputs.copy())\n",
        "        )\n",
        "\n",
        "        return reduced_outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        lr_lbmd = lambda _: max(\n",
        "            self.hparams.optimizer.lr_decay\n",
        "            ** (\n",
        "                int(\n",
        "                    self.global_step\n",
        "                    * self.hparams.batch_size\n",
        "                    / self.hparams.optimizer.decay_step\n",
        "                )\n",
        "            ),\n",
        "            lr_clip / self.hparams.optimizer.lr,\n",
        "        )\n",
        "        bn_lbmd = lambda _: max(\n",
        "            self.hparams.optimizer.bn_momentum\n",
        "            * self.hparams.optimizer.bnm_decay\n",
        "            ** (\n",
        "                int(\n",
        "                    self.global_step\n",
        "                    * self.hparams.batch_size\n",
        "                    / self.hparams.optimizer.decay_step\n",
        "                )\n",
        "            ),\n",
        "            bnm_clip,\n",
        "        )\n",
        "\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.hparams.optimizer.lr,\n",
        "            weight_decay=self.hparams.optimizer.weight_decay,\n",
        "        )\n",
        "        lr_scheduler = lr_sched.LambdaLR(optimizer, lr_lambda=lr_lbmd)\n",
        "        bnm_scheduler = BNMomentumScheduler(self, bn_lambda=bn_lbmd)\n",
        "\n",
        "        return [optimizer], [lr_scheduler, bnm_scheduler]\n",
        "\n",
        "    def _build_dataloader(self, mode=\"train\"):\n",
        "        train_transforms = transforms.Compose(\n",
        "            [\n",
        "                d_utils.PointcloudToTensor(),\n",
        "                d_utils.PointcloudScale(),\n",
        "                d_utils.PointcloudRotate(),\n",
        "                d_utils.PointcloudRotatePerturbation(),\n",
        "                d_utils.PointcloudTranslate(),\n",
        "                d_utils.PointcloudJitter(),\n",
        "                d_utils.PointcloudRandomInputDropout(),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        dset = ModelNet40Cls(\n",
        "            self.hparams.num_points,\n",
        "            transforms=train_transforms if mode == \"train\" else None,\n",
        "            train=mode == \"train\",\n",
        "        )\n",
        "        return DataLoader(\n",
        "            dset,\n",
        "            batch_size=self.hparams.batch_size,\n",
        "            shuffle=mode == \"train\",\n",
        "            num_workers=4,\n",
        "            pin_memory=True,\n",
        "            drop_last=mode == \"train\",\n",
        "        )\n",
        "\n",
        "    @pl.data_loader\n",
        "    def train_dataloader(self):\n",
        "        return self._build_dataloader(mode=\"train\")\n",
        "\n",
        "    @pl.data_loader\n",
        "    def val_dataloader(self):\n",
        "        return self._build_dataloader(mode=\"val\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/decorators.py:13: UserWarning: data_loader decorator deprecated in 0.7.0. Will remove 0.9.0\n",
            "  warnings.warn(w)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjZ4oiHGunU-"
      },
      "source": [
        "from typing import List, Optional, Tuple\n",
        "def build_shared_mlp(mlp_spec: List[int], bn: bool = True):\n",
        "    layers = []\n",
        "    for i in range(1, len(mlp_spec)):\n",
        "        layers.append(\n",
        "            nn.Conv2d(mlp_spec[i - 1], mlp_spec[i], kernel_size=1, bias=not bn)\n",
        "        )\n",
        "        if bn:\n",
        "            layers.append(nn.BatchNorm2d(mlp_spec[i]))\n",
        "        layers.append(nn.ReLU(True))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class _PointnetSAModuleBase(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_PointnetSAModuleBase, self).__init__()\n",
        "        self.npoint = None\n",
        "        self.groupers = None\n",
        "        self.mlps = None\n",
        "\n",
        "    def forward(\n",
        "        self, xyz: torch.Tensor, features: Optional[torch.Tensor]\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        r\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        xyz : torch.Tensor\n",
        "            (B, N, 3) tensor of the xyz coordinates of the features (1*1024*3)\n",
        "        features : torch.Tensor\n",
        "            (B, C, N) tensor of the descriptors of the the features  (1*C*1024)\n",
        "        Returns\n",
        "        -------\n",
        "        new_xyz : torch.Tensor\n",
        "            (B, npoint, 3) tensor of the new features' xyz  (1*512*3)\n",
        "        new_features : torch.Tensor\n",
        "            (B,  \\sum_k(mlps[k][-1]), npoint) tensor of the new_features descriptors (1*40*512)\n",
        "        \"\"\"\n",
        "\n",
        "        new_features_list = []\n",
        "\n",
        "        xyz_flipped = xyz.transpose(1, 2).contiguous()\n",
        "        new_xyz = (\n",
        "            pointnet2_utils.gather_operation(\n",
        "                xyz_flipped, pointnet2_utils.furthest_point_sample(xyz, self.npoint)\n",
        "            )\n",
        "            .transpose(1, 2)\n",
        "            .contiguous()\n",
        "            if self.npoint is not None\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        for i in range(len(self.groupers)):\n",
        "            new_features = self.groupers[i](\n",
        "                xyz, new_xyz, features\n",
        "            )  # (B, C, npoint, nsample)\n",
        "\n",
        "            new_features = self.mlps[i](new_features)  # (B, mlp[-1], npoint, nsample)\n",
        "            new_features = F.max_pool2d(\n",
        "                new_features, kernel_size=[1, new_features.size(3)]\n",
        "            )  # (B, mlp[-1], npoint, 1)\n",
        "            new_features = new_features.squeeze(-1)  # (B, mlp[-1], npoint)\n",
        "\n",
        "            new_features_list.append(new_features)\n",
        "\n",
        "        return new_xyz, torch.cat(new_features_list, dim=1)\n",
        "\n",
        "\n",
        "class PointnetSAModuleMSG(_PointnetSAModuleBase):\n",
        "    r\"\"\"Pointnet set abstrction layer with multiscale grouping\n",
        "    Parameters\n",
        "    ----------\n",
        "    npoint : int\n",
        "        Number of features\n",
        "    radii : list of float32\n",
        "        list of radii to group with\n",
        "    nsamples : list of int32\n",
        "        Number of samples in each ball query\n",
        "    mlps : list of list of int32\n",
        "        Spec of the pointnet before the global max_pool for each scale\n",
        "    bn : bool\n",
        "        Use batchnorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, npoint, radii, nsamples, mlps, bn=True, use_xyz=True):\n",
        "        # type: (PointnetSAModuleMSG, int, List[float], List[int], List[List[int]], bool, bool) -> None\n",
        "        super(PointnetSAModuleMSG, self).__init__()\n",
        "\n",
        "        assert len(radii) == len(nsamples) == len(mlps)\n",
        "\n",
        "        self.npoint = npoint\n",
        "        self.groupers = nn.ModuleList()\n",
        "        self.mlps = nn.ModuleList()\n",
        "        for i in range(len(radii)):\n",
        "            radius = radii[i]\n",
        "            nsample = nsamples[i]\n",
        "            self.groupers.append(\n",
        "                pointnet2_utils.QueryAndGroup(radius, nsample, use_xyz=use_xyz)\n",
        "                if npoint is not None\n",
        "                else pointnet2_utils.GroupAll(use_xyz)\n",
        "            )\n",
        "            mlp_spec = mlps[i]\n",
        "            if use_xyz:\n",
        "                mlp_spec[0] += 3\n",
        "\n",
        "            self.mlps.append(build_shared_mlp(mlp_spec, bn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMvmm48YW1i1"
      },
      "source": [
        "#PointnetSAModule： set abstrction layer 的参数\n",
        "class PointnetSAModule(PointnetSAModuleMSG):\n",
        "    r\"\"\"Pointnet set abstrction layer\n",
        "    Parameters\n",
        "    ----------\n",
        "    npoint : int\n",
        "        Number of features 数目\n",
        "    radius : float\n",
        "        Radius of ball 半径\n",
        "    nsample : int\n",
        "        Number of samples in the ball query 半径内的点的数目\n",
        "    mlp : list\n",
        "        Spec of the pointnet before the global max_pool\n",
        "    bn : bool\n",
        "        Use batchnorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mlp, npoint=None, radius=None, nsample=None, bn=True, use_xyz=True\n",
        "    ):\n",
        "        # type: (PointnetSAModule, List[int], int, float, int, bool, bool) -> None\n",
        "        super(PointnetSAModule, self).__init__(\n",
        "            mlps=[mlp],\n",
        "            npoint=npoint,\n",
        "            radii=[radius],\n",
        "            nsamples=[nsample],\n",
        "            bn=bn,\n",
        "            use_xyz=use_xyz,\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IplDhclSW2ws"
      },
      "source": [
        "class PointnetFPModule(nn.Module):\n",
        "    r\"\"\"Propigates the features of one set to another\n",
        "    Parameters\n",
        "    ----------\n",
        "    mlp : list\n",
        "        Pointnet module parameters\n",
        "    bn : bool\n",
        "        Use batchnorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mlp, bn=True):\n",
        "        # type: (PointnetFPModule, List[int], bool) -> None\n",
        "        super(PointnetFPModule, self).__init__()\n",
        "        self.mlp = build_shared_mlp(mlp, bn=bn)\n",
        "\n",
        "    def forward(self, unknown, known, unknow_feats, known_feats):\n",
        "        # type: (PointnetFPModule, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor) -> torch.Tensor\n",
        "        r\"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        unknown : torch.Tensor\n",
        "            (B, n, 3) tensor of the xyz positions of the unknown features\n",
        "        known : torch.Tensor\n",
        "            (B, m, 3) tensor of the xyz positions of the known features\n",
        "        unknow_feats : torch.Tensor\n",
        "            (B, C1, n) tensor of the features to be propigated to\n",
        "        known_feats : torch.Tensor\n",
        "            (B, C2, m) tensor of features to be propigated\n",
        "        Returns\n",
        "        -------\n",
        "        new_features : torch.Tensor\n",
        "            (B, mlp[-1], n) tensor of the features of the unknown features\n",
        "        \"\"\"\n",
        "\n",
        "        if known is not None:\n",
        "            dist, idx = pointnet2_utils.three_nn(unknown, known)\n",
        "            dist_recip = 1.0 / (dist + 1e-8)\n",
        "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
        "            weight = dist_recip / norm\n",
        "\n",
        "            interpolated_feats = pointnet2_utils.three_interpolate(\n",
        "                known_feats, idx, weight\n",
        "            )\n",
        "        else:\n",
        "            interpolated_feats = known_feats.expand(\n",
        "                *(known_feats.size()[0:2] + [unknown.size(1)])\n",
        "            )\n",
        "\n",
        "        if unknow_feats is not None:\n",
        "            new_features = torch.cat(\n",
        "                [interpolated_feats, unknow_feats], dim=1\n",
        "            )  # (B, C2 + C1, n)\n",
        "        else:\n",
        "            new_features = interpolated_feats\n",
        "\n",
        "        new_features = new_features.unsqueeze(-1)\n",
        "        new_features = self.mlp(new_features)\n",
        "\n",
        "        return new_features.squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MLBDqfytwWC"
      },
      "source": [
        "class PointNet2ClassificationSSG(pl.LightningModule):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hparams = args\n",
        "\n",
        "        self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        self.SA_modules = nn.ModuleList()\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                npoint=512,\n",
        "                radius=0.2,\n",
        "                nsample=64,\n",
        "                mlp=[3, 64, 64, 128],\n",
        "                use_xyz=self.hparams.model.use_xyz,\n",
        "            )\n",
        "        )\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                npoint=128,\n",
        "                radius=0.4,\n",
        "                nsample=64,\n",
        "                mlp=[128, 128, 128, 256],\n",
        "                use_xyz=self.hparams.model.use_xyz,\n",
        "            )\n",
        "        )\n",
        "        self.SA_modules.append(\n",
        "            PointnetSAModule(\n",
        "                mlp=[256, 256, 512, 1024], use_xyz=self.hparams.model.use_xyz\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(1024, 512, bias=False),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(512, 256, bias=False),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 40),\n",
        "        )\n",
        "        \n",
        "    def _break_up_pc(self, pc):\n",
        "        xyz = pc[..., 0:3].contiguous()\n",
        "        features = pc[..., 3:].transpose(1, 2).contiguous() if pc.size(-1) > 3 else None\n",
        "\n",
        "        return xyz, features\n",
        "\n",
        "    def forward(self, pointcloud):\n",
        "        r\"\"\"\n",
        "            Forward pass of the network\n",
        "            Parameters\n",
        "            ----------\n",
        "            pointcloud: Variable(torch.cuda.FloatTensor)\n",
        "                (B, N, 3 + input_channels) tensor\n",
        "                Point cloud to run predicts on\n",
        "                Each point in the point-cloud MUST\n",
        "                be formated as (x, y, z, features...)\n",
        "        \"\"\"\n",
        "        xyz, features = self._break_up_pc(pointcloud)\n",
        "\n",
        "        for module in self.SA_modules:\n",
        "            xyz, features = module(xyz, features)\n",
        "\n",
        "        return self.fc_layer(features.squeeze(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_JoKXN-t06G"
      },
      "source": [
        "dummy_point_cloud = torch.rand(2, 512, 3)\n",
        "dummy_object_classes = torch.randint(high=40, size=(2,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IB06BBVfhBd"
      },
      "source": [
        "from typing import List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyklKXyAfWrX"
      },
      "source": [
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Calculate Euclid distance between each two points.\n",
        "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
        "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
        "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
        "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
        "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: per-point square distance, [B, N, M]\n",
        "    \"\"\"\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MofWE5Xnfiub"
      },
      "source": [
        "a0 = torch.rand(1, 512, 3)\n",
        "b0 = torch.rand(1, 512, 3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLsuKWrmf7cp"
      },
      "source": [
        "dist0 = square_distance(a0, b0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Tnhzz8gBgM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38c50e77-cfd9-42f2-f81d-19396615a1fb"
      },
      "source": [
        "dist0.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmPpW9HugJuq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37cb2c93-7c2c-41e1-ec16-f8aa3a5c3b30"
      },
      "source": [
        "b1 = torch.rand(1, 64, 3)\n",
        "dist1 = square_distance(a0, b1)\n",
        "dist1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-r6Q0K-geZ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a997e75f-3bd5-4d6e-a066-659c9a9626fa"
      },
      "source": [
        "\n",
        "torch.sum(a0, -1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cMBcaCgidXS"
      },
      "source": [
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S] （或者是[B X S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbHktYsgQ02R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6063ad5-71f4-4b14-9525-716c44fa91a7"
      },
      "source": [
        "[1]*2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeZpSg49Ry6K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "daebd3ea-b2f8-45ea-8616-fc8de848b4c1"
      },
      "source": [
        "a = torch.arange(5)\n",
        "print('a：', a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a： tensor([0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoBJY7uR-4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "3c1a307a-1d5a-4116-8799-395a331a4da0"
      },
      "source": [
        "a.view(5, 1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0]],\n",
              "\n",
              "        [[1]],\n",
              "\n",
              "        [[2]],\n",
              "\n",
              "        [[3]],\n",
              "\n",
              "        [[4]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJMZdcn3SIJc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "98406890-ac5f-4303-c0c0-bfa2cf8a76d1"
      },
      "source": [
        "a.view(5, 1, 1).repeat(1, 2, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0],\n",
              "         [0, 0, 0]],\n",
              "\n",
              "        [[1, 1, 1],\n",
              "         [1, 1, 1]],\n",
              "\n",
              "        [[2, 2, 2],\n",
              "         [2, 2, 2]],\n",
              "\n",
              "        [[3, 3, 3],\n",
              "         [3, 3, 3]],\n",
              "\n",
              "        [[4, 4, 4],\n",
              "         [4, 4, 4]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlGC8lwo7oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a0b048da-b882-43f2-a174-7a5c09f43059"
      },
      "source": [
        "idx0 = torch.arange(512).repeat(3, 1)\n",
        "view_shape = list(idx0.shape)\n",
        "print(view_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe0jpFyk6gNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ff9c4944-8cd2-456c-b195-bbbdd1bfc3b9"
      },
      "source": [
        "view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "print(view_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfj7maqa6zhV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2eac2016-a828-4102-9f1a-101f5f9e0821"
      },
      "source": [
        "repeat_shape = list(idx0.shape)\n",
        "repeat_shape[0] = 1\n",
        "print('repeat_shape', repeat_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "repeat_shape [1, 512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAIMNE2B7EuJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6bdd1999-19e8-4450-c992-572d8513b52b"
      },
      "source": [
        "batch_indices = torch.arange(3, dtype=torch.long).view(view_shape).repeat(repeat_shape)\n",
        "print('batch_indices', batch_indices)\n",
        "print(batch_indices.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_indices tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [2, 2, 2,  ..., 2, 2, 2]])\n",
            "torch.Size([3, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbguhYpS7y-S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "4677b821-d5d3-4c44-a4ce-3550e6941706"
      },
      "source": [
        "batch_indices.long(), idx0.long()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 1, 1, 1],\n",
              "         [2, 2, 2,  ..., 2, 2, 2]]),\n",
              " tensor([[  0,   1,   2,  ..., 509, 510, 511],\n",
              "         [  0,   1,   2,  ..., 509, 510, 511],\n",
              "         [  0,   1,   2,  ..., 509, 510, 511]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uumpWOzfqMQJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "outputId": "466e620d-1b3b-479f-ab4b-0266cc47e46e"
      },
      "source": [
        "points0 = torch.rand(3, 1024, 3)\n",
        "new_points = points0[batch_indices, idx0, :]\n",
        "print('points0', points0)\n",
        "print('new_points', new_points)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "points0 tensor([[[0.6989, 0.9967, 0.0904],\n",
            "         [0.7578, 0.9562, 0.7620],\n",
            "         [0.5944, 0.6421, 0.4615],\n",
            "         ...,\n",
            "         [0.9596, 0.6343, 0.1422],\n",
            "         [0.8262, 0.3135, 0.7420],\n",
            "         [0.1190, 0.4086, 0.6637]],\n",
            "\n",
            "        [[0.4742, 0.6821, 0.8652],\n",
            "         [0.7306, 0.0478, 0.6693],\n",
            "         [0.2708, 0.3941, 0.0818],\n",
            "         ...,\n",
            "         [0.8244, 0.9031, 0.5429],\n",
            "         [0.0101, 0.4054, 0.8145],\n",
            "         [0.8775, 0.2921, 0.9876]],\n",
            "\n",
            "        [[0.4233, 0.5617, 0.6352],\n",
            "         [0.9891, 0.0732, 0.9106],\n",
            "         [0.6275, 0.7898, 0.8102],\n",
            "         ...,\n",
            "         [0.6580, 0.8335, 0.8425],\n",
            "         [0.2947, 0.7030, 0.7679],\n",
            "         [0.5393, 0.8973, 0.8553]]])\n",
            "new_points tensor([[[0.6989, 0.9967, 0.0904],\n",
            "         [0.7578, 0.9562, 0.7620],\n",
            "         [0.5944, 0.6421, 0.4615],\n",
            "         ...,\n",
            "         [0.5953, 0.0190, 0.9683],\n",
            "         [0.0036, 0.2304, 0.4267],\n",
            "         [0.9336, 0.9481, 0.4985]],\n",
            "\n",
            "        [[0.4742, 0.6821, 0.8652],\n",
            "         [0.7306, 0.0478, 0.6693],\n",
            "         [0.2708, 0.3941, 0.0818],\n",
            "         ...,\n",
            "         [0.2522, 0.1816, 0.7572],\n",
            "         [0.5397, 0.6978, 0.2563],\n",
            "         [0.6631, 0.4628, 0.8157]],\n",
            "\n",
            "        [[0.4233, 0.5617, 0.6352],\n",
            "         [0.9891, 0.0732, 0.9106],\n",
            "         [0.6275, 0.7898, 0.8102],\n",
            "         ...,\n",
            "         [0.7551, 0.2870, 0.4350],\n",
            "         [0.0774, 0.6777, 0.6252],\n",
            "         [0.7993, 0.4129, 0.1516]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZYWFtlOvXPf"
      },
      "source": [
        "def farthest_point_sample(xyz, npoint):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "        随机选取一个点为第一个点，找出与这个点最远的点（为第二个点），\n",
        "        再找出与第二个点距离最远的点（为第三个点）。。。直到找齐512个点\n",
        "        ？？？如果有两个点互为最远的点呢？？？\n",
        "\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)  \n",
        "                    #[B npoints] 个0 用于储存farthest点的index\n",
        "    distance = torch.ones(B, N).to(device) * 1e10           # [B N]\n",
        "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device) \n",
        "                             #在0~N中选出B个随机值作为初始位置[B]\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest #用于储存farthest点的index\n",
        "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)  \n",
        "                                 #每个Batch上 初始的中心点[B 1 3]\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1) #每个点与中心点的距离 [B N]\n",
        "        mask = dist < distance  #该距离小于10^10的点的位置为true\n",
        "        distance[mask] = dist[mask]  #距离小于10^10的点的位置 distance上的1换成dist上的值\n",
        "        farthest = torch.max(distance, -1)[1]\n",
        "    return centroids\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ag-DQNzC7pR"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo-fFs6V_Blm"
      },
      "source": [
        "xyz = torch.rand(1, 1024, 3)\n",
        "centroids = torch.zeros(1, 512)\n",
        "distance = torch.ones(1, 1024)\n",
        "farthest = torch.randint(0, 1024, (2,), dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7abkJegp_qfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8450b48-2c1e-436d-9fd6-13fa096cdcbe"
      },
      "source": [
        "print(farthest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([764, 287])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb4gbK4FkI4V"
      },
      "source": [
        "centroid = xyz[0 , farthest, :].view(1, 1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKV0puj7kj6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3de3ab96-1afa-4843-f6c2-41a5dfcb38bd"
      },
      "source": [
        "d0 = (xyz - centroid) ** 2\n",
        "d0.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1024, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMyENDehj36X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07c4a160-606a-4727-c0f6-dc585686583e"
      },
      "source": [
        "dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "print(dist.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPwI9frEme1g"
      },
      "source": [
        "#mask = dist < distance \n",
        "#distance[mask] = dist[mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRkiCaI-tks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2d35786c-d535-4914-9cbc-b8a484d8d82a"
      },
      "source": [
        "distance0 = torch.ones(10).long()\n",
        "dist0 = torch.arange(10)\n",
        "print(distance0)\n",
        "print(dist0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCyUQzQC-xHG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e3f2f88-5ed8-491a-a67e-8040a88b3583"
      },
      "source": [
        "dist1 = torch.arange(0, 20, step=2)\n",
        "print(dist1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JsHyU91D2JS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "675b1f7a-48fe-44a9-95a3-e0f054e4d0f2"
      },
      "source": [
        "mask = dist0 < dist1\n",
        "print(mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIa6G5U2D_Ny",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f3c0828-9222-4c2f-f4a5-de7a2a8762e0"
      },
      "source": [
        "distance0[mask] = dist0[mask]\n",
        "print(distance0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdjGVWjCoDdO"
      },
      "source": [
        "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    _, S, _ = new_xyz.shape\n",
        "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1]) \n",
        "                                             #1*512*1024\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "    group_idx[sqrdists > radius ** 2] = N #两点之间的距离如果大于半径， 则idx=1024\n",
        "\n",
        "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample] \n",
        "    #[0]是数据，[1]是index \n",
        "    #升序 从小到大，取最小的前两个（1*512*2）\n",
        "\n",
        "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
        "    mask = group_idx == N #true的点：对某个点来说，所有的点都在r之外。 其他的点为false\n",
        "    group_idx[mask] = group_first[mask] #true的点被换成原GROUP_Idx中第一个点 ？？？？\n",
        "\n",
        "    return group_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MmGGrdm2ePX"
      },
      "source": [
        "group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rmO6FNM3oen",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73b24a8a-d772-412e-d8ab-2a0608e0b325"
      },
      "source": [
        "group_idx0 = query_ball_point(0.1, 2, points0, new_points)\n",
        "print(group_idx0.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 512, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWi5PXtNWgeg"
      },
      "source": [
        "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D] ：带着每个点的feature？\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = npoint\n",
        "    fps_idx = farthest_point_sample(xyz, npoint) # 各个中心点的idx [B, npoint]\n",
        "    torch.cuda.empty_cache()\n",
        "    new_xyz = index_points(xyz, fps_idx) #各个中心点的坐标 [B, npoint， C]\n",
        "    torch.cuda.empty_cache()\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz) #各个中心点对应的neighbor的index [B, npoint, nsample]\n",
        "    torch.cuda.empty_cache()\n",
        "    grouped_xyz = index_points(xyz, idx) # 各个中心点对应的neighbor的坐标，[B, npoint, nsample, C]\n",
        "    torch.cuda.empty_cache()\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C) #\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points, idx)\n",
        "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) \n",
        "               # [B, npoint, nsample, C+D] 把feature接在坐标后面\n",
        "    else:\n",
        "        new_points = grouped_xyz_norm\n",
        "    if returnfps:\n",
        "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
        "    else:\n",
        "        return new_xyz, new_points\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhbb01aqbGnY"
      },
      "source": [
        "def sample_and_group_all(xyz, points):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, 1, 3] 一个全是0的tensor？？\n",
        "        new_points: sampled points data, [B, 1, N, 3+D]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    new_xyz = torch.zeros(B, 1, C).to(device) \n",
        "    grouped_xyz = xyz.view(B, 1, N, C)\n",
        "    if points is not None:\n",
        "        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hibdnrYyeCAG"
      },
      "source": [
        "class PointNetSetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
        "        super(PointNetSetAbstraction, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel #3\n",
        "        for out_channel in mlp: # [64, 128, 128, 256] --->64\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1)) #[3, 64]\n",
        "            self.mlp_bns.append(nn.BatchNorm2d(out_channel)) [64]\n",
        "            last_channel = out_channel [64]\n",
        "        self.group_all = group_all  #将整个点云group\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "            mlp:一组通道数如 [64，128，128，256]\n",
        "          \n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \"\"\"\n",
        "        xyz = xyz.permute(0, 2, 1)\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 2, 1)\n",
        "\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
        "        # new_xyz: sampled points position data, [B, npoint, C]\n",
        "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
        "        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint] 通道数为第二个，另外两个的顺序有关系吗？？？？\n",
        "        for i, conv in enumerate(self.mlp_convs): \n",
        "          #i 为计数，\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points =  F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, 2)[0]\n",
        "        new_xyz = new_xyz.permute(0, 2, 1)\n",
        "        return new_xyz, new_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsYmNZ_dkRc1"
      },
      "source": [
        "**x**   \n",
        "[ batch_size, channels, height_1, width_1 ]  \n",
        "batch_size 一个batch中样例的个数       2  \n",
        "channels 通道数，也就是当前层的深度 1  \n",
        "height_1, 图片的高  7  \n",
        "width_1, 图片的宽 3\n",
        "\n",
        "**Conv2d的参数**   \n",
        "[ channels, output, height_2, width_2 ]\n",
        "\n",
        "channels, 通道数，和上面保持一致，也就是当前层的深度  1  \n",
        "output 输出的深度                                 8  \n",
        "height_2, 过滤器filter的高                                                      2  \n",
        "width_2, 过滤器filter的宽\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teMYNoWh2Qh7"
      },
      "source": [
        "class PointNetSetAbstractionMsg(nn.Module):\n",
        "    def __init__(self, npoint, radius_list, nsample_list, in_channel, mlp_list):\n",
        "        super(PointNetSetAbstractionMsg, self).__init__()\n",
        "        self.npoint = npoint \n",
        "        self.radius_list = radius_list\n",
        "        self.nsample_list = nsample_list\n",
        "        self.conv_blocks = nn.ModuleList()\n",
        "        self.bn_blocks = nn.ModuleList()\n",
        "        for i in range(len(mlp_list)):\n",
        "            convs = nn.ModuleList()\n",
        "            bns = nn.ModuleList()\n",
        "            last_channel = in_channel + 3\n",
        "            for out_channel in mlp_list[i]:\n",
        "                convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "                bns.append(nn.BatchNorm2d(out_channel))\n",
        "                last_channel = out_channel\n",
        "            self.conv_blocks.append(convs)\n",
        "            self.bn_blocks.append(bns)\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \"\"\"\n",
        "        xyz = xyz.permute(0, 2, 1) #[B 1024 3]\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 2, 1)\n",
        "\n",
        "        B, N, C = xyz.shape\n",
        "        S = self.npoint       #512\n",
        "        new_xyz = index_points(xyz, farthest_point_sample(xyz, S)) #最远距离的npoints个点[B 512 3]\n",
        "        new_points_list = []\n",
        "        for i, radius in enumerate(self.radius_list): #一组半径\n",
        "            K = self.nsample_list[i] #每个半径值对应的sample个数为K\n",
        "            group_idx = query_ball_point(radius, K, xyz, new_xyz)\n",
        "            grouped_xyz = index_points(xyz, group_idx) #每个半径和k对应的点云分组\n",
        "            grouped_xyz -= new_xyz.view(B, S, 1, C)  #减去中心点 norm\n",
        "            if points is not None:\n",
        "                grouped_points = index_points(points, group_idx)\n",
        "                grouped_points = torch.cat([grouped_points, grouped_xyz], dim=-1)\n",
        "            else:\n",
        "                grouped_points = grouped_xyz\n",
        "\n",
        "            grouped_points = grouped_points.permute(0, 3, 2, 1)  # [B, D, K, S]\n",
        "            for j in range(len(self.conv_blocks[i])):     #每一组grouping都提取特征\n",
        "                conv = self.conv_blocks[i][j]\n",
        "                bn = self.bn_blocks[i][j]\n",
        "                grouped_points =  F.relu(bn(conv(grouped_points)))\n",
        "            new_points = torch.max(grouped_points, 2)[0]  # [B, D', S]\n",
        "            new_points_list.append(new_points) #特征所组成的list\n",
        "\n",
        "        new_xyz = new_xyz.permute(0, 2, 1)\n",
        "        new_points_concat = torch.cat(new_points_list, dim=1)\n",
        "        return new_xyz, new_points_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHx7sdejSNKH"
      },
      "source": [
        "class PointNetFeaturePropagation(nn.Module):\n",
        "    def __init__(self, in_channel, mlp):\n",
        "        super(PointNetFeaturePropagation, self).__init__()\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
        "            last_channel = out_channel\n",
        "\n",
        "    def forward(self, xyz1, xyz2, points1, points2):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz1: input points position data, [B, C, N]\n",
        "            xyz2: sampled input points position data, [B, C, S]\n",
        "            points1: input points data, [B, D, N]\n",
        "            points2: input points data, [B, D, S]  ：feature\n",
        "        Return:\n",
        "            new_points: upsampled points data, [B, D', N]\n",
        "        \"\"\"\n",
        "        xyz1 = xyz1.permute(0, 2, 1)\n",
        "        xyz2 = xyz2.permute(0, 2, 1)\n",
        "\n",
        "        points2 = points2.permute(0, 2, 1)\n",
        "        B, N, C = xyz1.shape\n",
        "        _, S, _ = xyz2.shape\n",
        "\n",
        "        if S == 1:\n",
        "            interpolated_points = points2.repeat(1, N, 1)\n",
        "        else:\n",
        "            dists = square_distance(xyz1, xyz2) #[B N M]\n",
        "            dists, idx = dists.sort(dim=-1)   #sampled点中与原input某一点最近的三个点\n",
        "            dists, idx = dists[:, :, :3], idx[:, :, :3]  # [B, N, 3]\n",
        "\n",
        "            dist_recip = 1.0 / (dists + 1e-8)\n",
        "            norm = torch.sum(dist_recip, dim=2, keepdim=True) #除了被操作的dim维度值降为1，\n",
        "                                        #其它维度与输入张量input相同\n",
        "            weight = dist_recip / norm\n",
        "            interpolated_points = torch.sum(index_points(points2, idx) * weight.view(B, N, 3, 1), dim=2)\n",
        "                                 #[B N 3 D] * [B N 3 1] = [B N 3 D], SUM:[B N D]\n",
        "        if points1 is not None:\n",
        "            points1 = points1.permute(0, 2, 1)\n",
        "            new_points = torch.cat([points1, interpolated_points], dim=-1) #dim=-1 \n",
        "        else:\n",
        "            new_points = interpolated_points #把这三个点的特征当成该点的特征\n",
        "\n",
        "        new_points = new_points.permute(0, 2, 1)\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points = F.relu(bn(conv(new_points)))\n",
        "        return new_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAk95jXrIkfb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmaGsBsuSQmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}