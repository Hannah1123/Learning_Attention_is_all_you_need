{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention_aftermeeting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqCD/45lFYBZpwomSPl0IG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hannah1123/Learning_Attention_is_all_you_need/blob/master/Attention_aftermeeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-lXtAGII4U"
      },
      "source": [
        "class clones(N):\n",
        "  return \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9NuxeHcHuAC"
      },
      "source": [
        "class Encoder(torch.nn.module):\n",
        "  def __init__(self, layer, N):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.layers = [layer]*N\n",
        "\n",
        "\n",
        "  def forword(self, ):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igcClcaMGKtB"
      },
      "source": [
        "import torch\n",
        "help(torch.nn.Conv2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye2BjvQkD_GK"
      },
      "source": [
        "nn.Conv2d的功能是：对由多个输入平面组成的输入信号进行二维卷积，以最简单的例子进行说明：\n",
        "\n",
        "输入信号的形式为(N,Cin,H,W)(N,C_{in},H,W)   \n",
        "N表示batch size，  \n",
        "Cin表示channel个数，即每个卷积层中卷积核的数量，RGB图片channel个数为3  \n",
        "H，W分别表示特征图的高和宽。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djf6CU-xIHs7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "370ce871-56c1-476e-f87b-44c1454c6b94"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PNet, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.conv2 = torch.nn.Conv2d(3, 32, 3, 1, 1)\n",
        "    self.rulu2 = torch.nn.ReLU()\n",
        "    self.maxpool1 = torch.nn.MaxPool2d(2, 1)\n",
        "    self.maxpool2 = torch.nn.MaxPool2d(2, 1)\n",
        "\n",
        "  def forword(x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.maxpool2(x)\n",
        "    return x\n",
        "\n",
        "model = PNet()\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (conv2): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (rulu2): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4svY3SAPnJy"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOq-hR0wPvJX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "2537a9f2-1dd8-462a-bfa7-e18e02ea545c"
      },
      "source": [
        "class clones(module, N):\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-396fb7b7c1ec>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Br5pjXdJOr"
      },
      "source": [
        "def clones(module, N):\n",
        "  return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1FsOb_eQ7fI"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, layer, N):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm()\n",
        "\n",
        "  def forword(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "      x = self.norm(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV28bEhhfNxQ"
      },
      "source": [
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, layer):\n",
        "    super(Layer, self).__init__()\n",
        "    self.LayerNorm = nn.LayerNorm()\n",
        "\n",
        "\n",
        "  def forword(self, x):\n",
        "    x = self.LayerNorm\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOKTasfriU5S"
      },
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "  def __init__(self, size):\n",
        "    super(SublayerConnection, self).__init__()\n",
        "    self.sublayer = LayerNorm(size)\n",
        "\n",
        "  def forword(self, x):\n",
        "    return x + self.sublayer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mheCYRi_jkec"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, ):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.atten = Attention(sublayer)\n",
        "    self.norm = LayerNorm(size)\n",
        "    self.sublayerconnection = SublayerConnection()\n",
        "\n",
        "  def forword(self, ):\n",
        "    x = self.atten(x)\n",
        "    x = slef.sublayerconnection(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u96ir-op_asn"
      },
      "source": [
        "decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J4RFkcw_cEE"
      },
      "source": [
        "class DEcoder(nn.Module):\n",
        "  def __init__(self, layer, N):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.layers = clones(layer, N)\n",
        "    self.norm = LayerNorm()\n",
        "\n",
        "  def forword(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "      x = self.norm(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpG4Ja-UrXrS"
      },
      "source": [
        "##attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_cg9hiotQgx"
      },
      "source": [
        "def attention(quary, key, value, mask=None, dropout=None):\n",
        "\n",
        "  d_k = query.size(-1)\n",
        "  scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "  #matmul：高维向量乘法  transpose：转置最后一维和倒数第二维换位置 \n",
        "  if mask is not None:\n",
        "    scores = scores.masked_fill(mask == 0, -1e9)\n",
        "  p_attn = F.softmax(scores, dim = -1) \n",
        "  # dim=0表示按列计算；dim=1表示按行计算，dim=-1,即,以最后一个维度作为一维向量计算softmax\n",
        "  if dropout is not None:\n",
        "    p_attn = dropout(p_attn)\n",
        "  return torch.matmul(p_atten, value), p_attn\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzKOAVXe1LyK"
      },
      "source": [
        "scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7tJLYa8wQbD"
      },
      "source": [
        "import torch\n",
        "a = torch.ones(3, 4)\n",
        "b = torch.ones(5, 4, 2)\n",
        "c = torch.ones(2, 3)\n",
        "print('a', a)\n",
        "print('b', b)\n",
        "print('c', c)\n",
        "\n",
        "y = torch.matmul(c, a)\n",
        "print('y', y)\n",
        "x = torch.matmul(a, b)\n",
        "print('x', x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED9orY9Rr442"
      },
      "source": [
        "EMBEDDING_DIM = 512 \n",
        "DIM_FF = 2048\n",
        "DIM_Q = DIM_K = DIM_V= 64\n",
        "NUM_OF_HEAD = 8\n",
        "EXPECTED_MAX_NUM_WORD = 100 #??\n",
        "BATCH_SIZE = 32 #RANDOM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXpZbp2TraHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "223db003-4baf-4291-ea00-665dd3375aa9"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "input = torch.randn(BATCH_SIZE, EXPECTED_MAX_NUM_WORD, EMBEDDING_DIM)\n",
        "w_q = torch.randn(EMBEDDING_DIM, DIM_Q)\n",
        "w_k = torch.randn(EMBEDDING_DIM, DIM_K)\n",
        "w_v = torch.randn(EMBEDDING_DIM, DIM_V)\n",
        "# .view()即reshape\n",
        "query = torch.matmul(input.view(BATCH_SIZE*EXPECTED_MAX_NUM_WORD, EMBEDDING_DIM), w_q)\n",
        "query = query.view(BATCH_SIZE, EXPECTED_MAX_NUM_WORD, DIM_Q)\n",
        "query_1 = torch.matmul(input, w_q)\n",
        "print(torch.all(query==query_1))\n",
        "\n",
        "key = torch.matmul(input, w_k)\n",
        "value = torch.matmul(input, w_v)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7rRJWX1S2P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9cecce2f-68b8-45fe-e7ec-b2f7d8e3a39a"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "d_k = query.size(-1)\n",
        "scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "print(query.shape)\n",
        "print(key.shape)\n",
        "print(key.transpose(-1, -2).shape)\n",
        "print(scores.shape)\n",
        "print(torch.all(scores[0]==torch.matmul(query[0], key.transpose(-1,-2)[0]/np.sqrt(DIM_Q))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 100, 64])\n",
            "torch.Size([32, 100, 64])\n",
            "torch.Size([32, 64, 100])\n",
            "torch.Size([32, 100, 100])\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KfZUq0Wc2an"
      },
      "source": [
        "##multihead attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdAcZaNqaYj4"
      },
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "  def __init__(self, h, d_model, dropout=0.1):\n",
        "    super(MultiHeadedAttention, self).__init__()\n",
        "    assert d_model % h == 0 \n",
        "    #假设 d_v 永远等于 d_k \n",
        "    self.d_k = d_model // h  #减少维度使总计算量相当于single-head用全维度计算 512/8=64维\n",
        "    self.h = h   #取h=8\n",
        "    self.attn = None\n",
        "    self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "  def forward(self, query, key, value, mask=None):\n",
        "    if mask is not None:\n",
        "      #同一个mask 用于所有h head\n",
        "      mask = mask.unsqueeze(1) #在1的位置加入维度为1的维度，如原来为（4，3），就变为（4，1，3） \n",
        "    nbatches = query.size(0)  #0维上的元素个数\n",
        "  \n",
        "    \"1）线性投影 从d_model到 h*d_k\"\n",
        "    query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]\n",
        "                 # view（）函数：重塑张量维形状(nbatches, -1, self.h, self.d_k)，（-1表示未知，由计算机自己算），之后 转置（1，2）\n",
        "\n",
        "    \"2）应用attention到投影向量上\"\n",
        "    x, self.attn = attention(query, key, value, mask=mask, dropout = self.dropout)\n",
        "\n",
        "    \"3）Concat using a view and apply a final linear. \"\n",
        "    x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h*self.d_k)\n",
        "    return self.linears[-1](x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5QV6OWzf4k-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b1857cf-35c0-43dd-d4c8-49dbcf9b7a15"
      },
      "source": [
        "x = torch.randn(128, 20)  # 输入的维度是（128，20）\n",
        "m = torch.nn.Linear(20, 30)  # 20,30是指维度\n",
        "output0 = m(x)\n",
        "output0.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 30])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQs3WExmb-Qz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "02009a50-3815-4fb7-b7f9-9f8e03b23137"
      },
      "source": [
        "#linear function: 把query变成可学习的参数\n",
        "#linears = clones(nn.Linear(d_model, d_model), 4)\n",
        "l = nn.Linear(64, 64)\n",
        "x = query\n",
        "output = l(x)\n",
        "print('query.shape:', query.shape)\n",
        "print('output.shape:', output.shape)\n",
        "#query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "query.shape: torch.Size([32, 100, 64])\n",
            "output.shape: torch.Size([32, 100, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oek_fGvhgKgY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4903f5ab-4034-41c5-c43a-d469d4402406"
      },
      "source": [
        "query.size(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9RTkk_8gvEf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "866b2c7a-bf4c-47b4-bd31-6b01e6974776"
      },
      "source": [
        "nbatches = query.size(0)\n",
        "d_k = 64\n",
        "h = 4\n",
        "query = l(x).view(nbatches, -1, h, d_k).transpose(1, 2)\n",
        "query.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 4, 25, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1bGagL7iO52"
      },
      "source": [
        "linears = clones(nn.Linear(64, 64), 4)\n",
        "query, key, value = [l(x).view(nbatches, -1, h, d_k).transpose(1, 2) for l, x in zip(linears, (query, key, value))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G44nkvTJkVfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "99757915-bf23-4010-c5c4-b17db01610d2"
      },
      "source": [
        "x, attn = attention(query, key, value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5d2bdff4bbab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-5b02e2172421>\u001b[0m in \u001b[0;36mattention\u001b[0;34m(quary, key, value, mask, dropout)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mp_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_atten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'p_atten' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXutgtXvaqgJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "2d5319ea-0879-4b26-f345-fd038590e477"
      },
      "source": [
        "t = torch.arange(320).reshape(10, 32)\n",
        "print('t:', t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t: tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
            "          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
            "          28,  29,  30,  31],\n",
            "        [ 32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
            "          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
            "          60,  61,  62,  63],\n",
            "        [ 64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
            "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
            "          92,  93,  94,  95],\n",
            "        [ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
            "         110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
            "         124, 125, 126, 127],\n",
            "        [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
            "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
            "         156, 157, 158, 159],\n",
            "        [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
            "         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187,\n",
            "         188, 189, 190, 191],\n",
            "        [192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
            "         206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
            "         220, 221, 222, 223],\n",
            "        [224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
            "         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
            "         252, 253, 254, 255],\n",
            "        [256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
            "         270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
            "         284, 285, 286, 287],\n",
            "        [288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
            "         302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
            "         316, 317, 318, 319]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSqk_GYSCQ34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "outputId": "dc3c1b15-e84c-43b5-e6a4-68e8e14fc554"
      },
      "source": [
        "t0 = t.view(10, 4, 8)\n",
        "print('t0:', t0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t0: tensor([[[  0,   1,   2,   3,   4,   5,   6,   7],\n",
            "         [  8,   9,  10,  11,  12,  13,  14,  15],\n",
            "         [ 16,  17,  18,  19,  20,  21,  22,  23],\n",
            "         [ 24,  25,  26,  27,  28,  29,  30,  31]],\n",
            "\n",
            "        [[ 32,  33,  34,  35,  36,  37,  38,  39],\n",
            "         [ 40,  41,  42,  43,  44,  45,  46,  47],\n",
            "         [ 48,  49,  50,  51,  52,  53,  54,  55],\n",
            "         [ 56,  57,  58,  59,  60,  61,  62,  63]],\n",
            "\n",
            "        [[ 64,  65,  66,  67,  68,  69,  70,  71],\n",
            "         [ 72,  73,  74,  75,  76,  77,  78,  79],\n",
            "         [ 80,  81,  82,  83,  84,  85,  86,  87],\n",
            "         [ 88,  89,  90,  91,  92,  93,  94,  95]],\n",
            "\n",
            "        [[ 96,  97,  98,  99, 100, 101, 102, 103],\n",
            "         [104, 105, 106, 107, 108, 109, 110, 111],\n",
            "         [112, 113, 114, 115, 116, 117, 118, 119],\n",
            "         [120, 121, 122, 123, 124, 125, 126, 127]],\n",
            "\n",
            "        [[128, 129, 130, 131, 132, 133, 134, 135],\n",
            "         [136, 137, 138, 139, 140, 141, 142, 143],\n",
            "         [144, 145, 146, 147, 148, 149, 150, 151],\n",
            "         [152, 153, 154, 155, 156, 157, 158, 159]],\n",
            "\n",
            "        [[160, 161, 162, 163, 164, 165, 166, 167],\n",
            "         [168, 169, 170, 171, 172, 173, 174, 175],\n",
            "         [176, 177, 178, 179, 180, 181, 182, 183],\n",
            "         [184, 185, 186, 187, 188, 189, 190, 191]],\n",
            "\n",
            "        [[192, 193, 194, 195, 196, 197, 198, 199],\n",
            "         [200, 201, 202, 203, 204, 205, 206, 207],\n",
            "         [208, 209, 210, 211, 212, 213, 214, 215],\n",
            "         [216, 217, 218, 219, 220, 221, 222, 223]],\n",
            "\n",
            "        [[224, 225, 226, 227, 228, 229, 230, 231],\n",
            "         [232, 233, 234, 235, 236, 237, 238, 239],\n",
            "         [240, 241, 242, 243, 244, 245, 246, 247],\n",
            "         [248, 249, 250, 251, 252, 253, 254, 255]],\n",
            "\n",
            "        [[256, 257, 258, 259, 260, 261, 262, 263],\n",
            "         [264, 265, 266, 267, 268, 269, 270, 271],\n",
            "         [272, 273, 274, 275, 276, 277, 278, 279],\n",
            "         [280, 281, 282, 283, 284, 285, 286, 287]],\n",
            "\n",
            "        [[288, 289, 290, 291, 292, 293, 294, 295],\n",
            "         [296, 297, 298, 299, 300, 301, 302, 303],\n",
            "         [304, 305, 306, 307, 308, 309, 310, 311],\n",
            "         [312, 313, 314, 315, 316, 317, 318, 319]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd4c8FwVCnhX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "fb7f59d0-bdfa-4126-8408-c4e134ab72b4"
      },
      "source": [
        "t1 = t0.transpose(0, 1)\n",
        "print('t1:', t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t1: tensor([[[  0,   1,   2,   3,   4,   5,   6,   7],\n",
            "         [ 32,  33,  34,  35,  36,  37,  38,  39],\n",
            "         [ 64,  65,  66,  67,  68,  69,  70,  71],\n",
            "         [ 96,  97,  98,  99, 100, 101, 102, 103],\n",
            "         [128, 129, 130, 131, 132, 133, 134, 135],\n",
            "         [160, 161, 162, 163, 164, 165, 166, 167],\n",
            "         [192, 193, 194, 195, 196, 197, 198, 199],\n",
            "         [224, 225, 226, 227, 228, 229, 230, 231],\n",
            "         [256, 257, 258, 259, 260, 261, 262, 263],\n",
            "         [288, 289, 290, 291, 292, 293, 294, 295]],\n",
            "\n",
            "        [[  8,   9,  10,  11,  12,  13,  14,  15],\n",
            "         [ 40,  41,  42,  43,  44,  45,  46,  47],\n",
            "         [ 72,  73,  74,  75,  76,  77,  78,  79],\n",
            "         [104, 105, 106, 107, 108, 109, 110, 111],\n",
            "         [136, 137, 138, 139, 140, 141, 142, 143],\n",
            "         [168, 169, 170, 171, 172, 173, 174, 175],\n",
            "         [200, 201, 202, 203, 204, 205, 206, 207],\n",
            "         [232, 233, 234, 235, 236, 237, 238, 239],\n",
            "         [264, 265, 266, 267, 268, 269, 270, 271],\n",
            "         [296, 297, 298, 299, 300, 301, 302, 303]],\n",
            "\n",
            "        [[ 16,  17,  18,  19,  20,  21,  22,  23],\n",
            "         [ 48,  49,  50,  51,  52,  53,  54,  55],\n",
            "         [ 80,  81,  82,  83,  84,  85,  86,  87],\n",
            "         [112, 113, 114, 115, 116, 117, 118, 119],\n",
            "         [144, 145, 146, 147, 148, 149, 150, 151],\n",
            "         [176, 177, 178, 179, 180, 181, 182, 183],\n",
            "         [208, 209, 210, 211, 212, 213, 214, 215],\n",
            "         [240, 241, 242, 243, 244, 245, 246, 247],\n",
            "         [272, 273, 274, 275, 276, 277, 278, 279],\n",
            "         [304, 305, 306, 307, 308, 309, 310, 311]],\n",
            "\n",
            "        [[ 24,  25,  26,  27,  28,  29,  30,  31],\n",
            "         [ 56,  57,  58,  59,  60,  61,  62,  63],\n",
            "         [ 88,  89,  90,  91,  92,  93,  94,  95],\n",
            "         [120, 121, 122, 123, 124, 125, 126, 127],\n",
            "         [152, 153, 154, 155, 156, 157, 158, 159],\n",
            "         [184, 185, 186, 187, 188, 189, 190, 191],\n",
            "         [216, 217, 218, 219, 220, 221, 222, 223],\n",
            "         [248, 249, 250, 251, 252, 253, 254, 255],\n",
            "         [280, 281, 282, 283, 284, 285, 286, 287],\n",
            "         [312, 313, 314, 315, 316, 317, 318, 319]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxrmOTomDa1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "7327bce7-59d9-4833-dfae-fc077cf9947f"
      },
      "source": [
        "t2 = t.view(4, 10, 8)\n",
        "print('t2:', t2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t2: tensor([[[  0,   1,   2,   3,   4,   5,   6,   7],\n",
            "         [  8,   9,  10,  11,  12,  13,  14,  15],\n",
            "         [ 16,  17,  18,  19,  20,  21,  22,  23],\n",
            "         [ 24,  25,  26,  27,  28,  29,  30,  31],\n",
            "         [ 32,  33,  34,  35,  36,  37,  38,  39],\n",
            "         [ 40,  41,  42,  43,  44,  45,  46,  47],\n",
            "         [ 48,  49,  50,  51,  52,  53,  54,  55],\n",
            "         [ 56,  57,  58,  59,  60,  61,  62,  63],\n",
            "         [ 64,  65,  66,  67,  68,  69,  70,  71],\n",
            "         [ 72,  73,  74,  75,  76,  77,  78,  79]],\n",
            "\n",
            "        [[ 80,  81,  82,  83,  84,  85,  86,  87],\n",
            "         [ 88,  89,  90,  91,  92,  93,  94,  95],\n",
            "         [ 96,  97,  98,  99, 100, 101, 102, 103],\n",
            "         [104, 105, 106, 107, 108, 109, 110, 111],\n",
            "         [112, 113, 114, 115, 116, 117, 118, 119],\n",
            "         [120, 121, 122, 123, 124, 125, 126, 127],\n",
            "         [128, 129, 130, 131, 132, 133, 134, 135],\n",
            "         [136, 137, 138, 139, 140, 141, 142, 143],\n",
            "         [144, 145, 146, 147, 148, 149, 150, 151],\n",
            "         [152, 153, 154, 155, 156, 157, 158, 159]],\n",
            "\n",
            "        [[160, 161, 162, 163, 164, 165, 166, 167],\n",
            "         [168, 169, 170, 171, 172, 173, 174, 175],\n",
            "         [176, 177, 178, 179, 180, 181, 182, 183],\n",
            "         [184, 185, 186, 187, 188, 189, 190, 191],\n",
            "         [192, 193, 194, 195, 196, 197, 198, 199],\n",
            "         [200, 201, 202, 203, 204, 205, 206, 207],\n",
            "         [208, 209, 210, 211, 212, 213, 214, 215],\n",
            "         [216, 217, 218, 219, 220, 221, 222, 223],\n",
            "         [224, 225, 226, 227, 228, 229, 230, 231],\n",
            "         [232, 233, 234, 235, 236, 237, 238, 239]],\n",
            "\n",
            "        [[240, 241, 242, 243, 244, 245, 246, 247],\n",
            "         [248, 249, 250, 251, 252, 253, 254, 255],\n",
            "         [256, 257, 258, 259, 260, 261, 262, 263],\n",
            "         [264, 265, 266, 267, 268, 269, 270, 271],\n",
            "         [272, 273, 274, 275, 276, 277, 278, 279],\n",
            "         [280, 281, 282, 283, 284, 285, 286, 287],\n",
            "         [288, 289, 290, 291, 292, 293, 294, 295],\n",
            "         [296, 297, 298, 299, 300, 301, 302, 303],\n",
            "         [304, 305, 306, 307, 308, 309, 310, 311],\n",
            "         [312, 313, 314, 315, 316, 317, 318, 319]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBsbRhoLW4xB"
      },
      "source": [
        "##Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDVTEg72W3Wb"
      },
      "source": [
        "我们需要建立神经网络通过learning的办法修改word embedding里面的参数使得word embedding每一个词向量能够表示每一个不同的词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r59znPSHXq2"
      },
      "source": [
        "class Embedding(nn.Module):\n",
        "  def __init__(self, vocab, d_model):\n",
        "    super(Embedding, self).__init__()\n",
        "    self.vocab = vocab\n",
        "    self.d_model = d_model\n",
        "    self.embed = nn.Embedding(vocab, d_model) #每句话里有几个单词， 每个单词的维度\n",
        "\n",
        "  def forward(self. x):\n",
        "    x = self.embed(x)\n",
        "  return x * math.sqrt(self.d_model) # ??\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwVS3sRrJ6CF"
      },
      "source": [
        "##Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXy-zRs0KAaR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d027bf6-c0e2-489d-8a61-fe9d54eaa0f9"
      },
      "source": [
        "torch.arange(0, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbGlcTwnNWJf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa3af3c2-51ce-4a1a-9b87-478057576392"
      },
      "source": [
        "p = torch.arange(0, 10).unsqueeze(1)\n",
        "p.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Z2yjkQNf58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f5fdcbf9-42c1-4cc1-debb-ccf533e8d8fa"
      },
      "source": [
        "torch.arange(0, 64, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34,\n",
              "        36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r-9saP_Rv_m"
      },
      "source": [
        "torch.arange(0, 64, 2) * -(math.log(10000.0) / 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlDO9hpN5Yv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7dc40261-5b5c-4227-b74f-b394b57db6a2"
      },
      "source": [
        "torch.exp(torch.arange(0, 64, 2) * -(math.log(10000.0) / 64))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000e+00, 7.4989e-01, 5.6234e-01, 4.2170e-01, 3.1623e-01, 2.3714e-01,\n",
              "        1.7783e-01, 1.3335e-01, 1.0000e-01, 7.4989e-02, 5.6234e-02, 4.2170e-02,\n",
              "        3.1623e-02, 2.3714e-02, 1.7783e-02, 1.3335e-02, 1.0000e-02, 7.4989e-03,\n",
              "        5.6234e-03, 4.2170e-03, 3.1623e-03, 2.3714e-03, 1.7783e-03, 1.3335e-03,\n",
              "        1.0000e-03, 7.4989e-04, 5.6234e-04, 4.2170e-04, 3.1623e-04, 2.3714e-04,\n",
              "        1.7783e-04, 1.3335e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zJBzXySlmzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "961f7b19-b539-43c6-deaa-b4196374165e"
      },
      "source": [
        "div = torch.exp(torch.exp(torch.arange(0, 64, 2) * -(math.log(10000.0) / 64)))\n",
        "div.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xprbxLSelyBS"
      },
      "source": [
        "pe = torch.zeros(5000, 64)\n",
        "position = torch.arange(0, 5000).unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XK3LCsHmYXa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60eb0d8a-8a4e-4c85-9d0d-6b8ed4a3fdc6"
      },
      "source": [
        "pe[:, 0::2] = torch.sin(position * div) #偶数位\n",
        "pe[:, 1::2] = torch.cos(position * div)\n",
        "pe.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Nxxc7UmyNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "319c42e9-9484-4886-cc2a-0451dfbdfd86"
      },
      "source": [
        "pe = pe.unsqueeze(0)\n",
        "pe.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5000, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJCgVznDo3tJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "a56d9ce3-2f25-4343-ed69-63d7b34939ad"
      },
      "source": [
        "print(pe[0][100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0.9968, -0.0803, -0.9287, -0.3708, -0.4364,  0.8998,  0.9962, -0.0872,\n",
            "        -0.8603,  0.5098,  0.8902,  0.4555,  0.0814,  0.9967,  0.9199,  0.3921,\n",
            "        -0.5323, -0.8465,  0.8266,  0.5627, -0.8571,  0.5152, -0.5928, -0.8053,\n",
            "         0.4437, -0.8962,  0.9559, -0.2936,  0.9531,  0.3028,  0.7253,  0.6884,\n",
            "         0.4565,  0.8897,  0.2199,  0.9755,  0.0329,  0.9995, -0.1082,  0.9941,\n",
            "        -0.2126,  0.9771, -0.2893,  0.9572, -0.3457,  0.9383, -0.3871,  0.9220,\n",
            "        -0.4177,  0.9086, -0.4403,  0.8978, -0.4571,  0.8894, -0.4696,  0.8829,\n",
            "        -0.4788,  0.8779, -0.4858,  0.8741, -0.4910,  0.8712, -0.4948,  0.8690])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UIdKvWco_VP"
      },
      "source": [
        "class PositionEncoding(nn.Module):\n",
        "  def __init__(self, d_model, max_len=5000, droput):\n",
        "    super(PositionEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout()\n",
        "\n",
        "    position = torch.arange(0, max_len).unsqueeze(1)\n",
        "    div = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000) / d_model))\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    pe[:, 0::2] = sin(position * div)\n",
        "    pe[:, 1::2] = cos(position * div)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7jP_i8u4RKy"
      },
      "source": [
        "疑问1：为什么不把参数都设置为nn.Parameter类型，只是把不需要更新参数的设置 requires_grad=False?\n",
        "\n",
        "疑问2：为什么不直接将不需要进行参数修改的变量作为模型类的成员变量就好了，还要进行注册?\n",
        "\n",
        "对于疑问1我没找到答案，疑问2有两个原因:\n",
        "\n",
        "不进行注册，参数不能保存到 OrderDict，也就无法进行保存\n",
        "模型进行参数在CPU和GPU移动时, 执行 model.to(device) ，注册后的参数也会自动进行设备移动"
      ]
    }
  ]
}